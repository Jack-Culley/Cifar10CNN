{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10CNN",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8IlkFDmrp_2"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import time\n",
        "from datetime import timedelta\n",
        "import math\n",
        "import os\n",
        "import keras\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "assert x_train.shape == (50000, 32, 32, 3)\n",
        "assert x_test.shape == (10000, 32, 32, 3)\n",
        "assert y_train.shape == (50000, 1)\n",
        "assert y_test.shape == (10000, 1)"
      ],
      "metadata": {
        "id": "6G47azpQrzze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network using Tensorflow"
      ],
      "metadata": {
        "id": "geTpgGw3r9vE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Rescaling\n",
        "from keras.utils import np_utils\n",
        "\n",
        "#one hot encode\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "# datagen = ImageDataGenerator(\n",
        "#     featurewise_center = True,\n",
        "#     samplewise_center = False,\n",
        "#     featurewise_std_normalization=True,\n",
        "#     samplewise_std_normalization=False,\n",
        "#     zca_whitening=True,\n",
        "#     rotation_range=90,\n",
        "#     width_shift_range=0.1,\n",
        "#     height_shift_range=0.1,\n",
        "#     horizontal_flip=True,\n",
        "#     vertical_flip=True,\n",
        "#     rescale=None\n",
        "# )\n",
        "\n",
        "# datagen.fit(x_train)\n",
        "\n",
        "Rescale = Rescaling(1./127.5, offset=-1)\n",
        "x_test_r = Rescale(x_test)"
      ],
      "metadata": {
        "id": "bxTVg8KTr0ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_norm = x_train/255 - 0.5\n",
        "x_test_norm = x_test/255 - 0.5"
      ],
      "metadata": {
        "id": "dQcP5WmIsEPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "\n",
        "CNNmodel = models.Sequential()\n",
        "#first param is number of filters\n",
        "CNNmodel.add(layers.Conv2D(32, (3,3), input_shape=(32,32,3), padding='same'))\n",
        "#CNNmodel.add(layers.LeakyReLU(alpha=0.35))\n",
        "CNNmodel.add(layers.Activation(\"elu\"))\n",
        "CNNmodel.add(layers.BatchNormalization())\n",
        "\n",
        "\n",
        "CNNmodel.add(layers.Conv2D(32, (3,3), padding='same'))\n",
        "CNNmodel.add(layers.Activation(\"elu\"))\n",
        "\n",
        "#CNNmodel.add(layers.LeakyReLU(alpha=0.35))\n",
        "CNNmodel.add(layers.BatchNormalization())\n",
        "\n",
        "CNNmodel.add(layers.MaxPooling2D(2,2))\n",
        "# CNNmodel.add(layers.BatchNormalization())\n",
        "#CNNmodel.add(layers.Activation(\"relu\"))\n",
        "CNNmodel.add(layers.Dropout(0.4))\n",
        "\n",
        "\n",
        "CNNmodel.add(layers.Conv2D(64, (3,3), padding='same'))\n",
        "#CNNmodel.add(layers.LeakyReLU(alpha=0.35))\n",
        "CNNmodel.add(layers.Activation(\"elu\"))\n",
        "CNNmodel.add(layers.BatchNormalization())\n",
        "\n",
        "CNNmodel.add(layers.Conv2D(64, (3,3), padding='same'))\n",
        "CNNmodel.add(layers.Activation(\"elu\"))\n",
        "CNNmodel.add(layers.BatchNormalization())\n",
        "\n",
        "CNNmodel.add(layers.MaxPooling2D(2,2))\n",
        "# CNNmodel.add(layers.BatchNormalization())\n",
        "#CNNmodel.add(layers.LeakyReLU(alpha=0.35))\n",
        "CNNmodel.add(layers.Dropout(0.4))\n",
        "\n",
        "CNNmodel.add(layers.Conv2D(128, (3,3), padding='same'))\n",
        "#CNNmodel.add(layers.LeakyReLU(alpha=0.35))\n",
        "CNNmodel.add(layers.Activation(\"elu\"))\n",
        "CNNmodel.add(layers.BatchNormalization())\n",
        "\n",
        "CNNmodel.add(layers.Conv2D(128, (3,3), padding='same'))\n",
        "CNNmodel.add(layers.Activation(\"elu\"))\n",
        "CNNmodel.add(layers.BatchNormalization())\n",
        "\n",
        "CNNmodel.add(layers.MaxPooling2D(2,2))\n",
        "CNNmodel.add(layers.Dropout(0.4))\n",
        "\n",
        "CNNmodel.summary()"
      ],
      "metadata": {
        "id": "B1ISwZyKsHK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNNmodel.add(layers.Flatten())\n",
        "CNNmodel.add(layers.Dense(10, activation=\"softmax\", kernel_regularizer=\"l2\", bias_regularizer='l2'))\n",
        "#CNNmodel.add(layers.Activation(\"relu\"))\n",
        "\n",
        "CNNmodel.summary()"
      ],
      "metadata": {
        "id": "uX4xs1ufsPA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNNmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
        "CNNmodel.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
        "\n",
        "#history = CNNmodel.fit(datagen.flow(x_train, y_train, batch_size=32), epochs=14, validation_data=(x_test_r, y_test))\n",
        "history = CNNmodel.fit(x_train_norm, y_train, batch_size=64, epochs=125, validation_data=(x_test_norm, y_test))"
      ],
      "metadata": {
        "id": "Yzx45ouVsSH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#plot to show each epochs validation accuracy and train accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TA7V-rYEsXuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNNtest = CNNmodel.predict(x_test_norm)\n",
        "CNNtest_labels = np.argmax(CNNtest, axis=1)\n",
        "\n",
        "y_test.reshape(10000,)\n",
        "accuracy = metrics.accuracy_score(CNNtest_labels, y_test)\n",
        "print('{:.2f}'.format(accuracy*100) + '%')"
      ],
      "metadata": {
        "id": "bRkekTwPsZ-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "dump(CNNmodel, 'cifar10.joblib')"
      ],
      "metadata": {
        "id": "Kd8FInVtsaFT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}